{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafa239e-8205-44c6-a345-eb4da4ad55bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Selecting rows from exams table\n",
      "  size_category  count\n",
      "0       1.0-1.5     27\n",
      "1          <1cm     39\n",
      "2        >1.5cm     68\n",
      "3      negative   1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/66y8yr891nx_wrg5vxt9ppy00000gp/T/ipykernel_14785/1526797899.py:70: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Selecting rows from exams table\n",
      "0       negative\n",
      "1       negative\n",
      "2       negative\n",
      "3       negative\n",
      "4       negative\n",
      "          ...   \n",
      "2721    negative\n",
      "2722    negative\n",
      "2723    negative\n",
      "2724    negative\n",
      "2725    negative\n",
      "Name: size_category, Length: 2726, dtype: object\n",
      "  size_category  count\n",
      "0       1.0-1.5     35\n",
      "1          <1cm     26\n",
      "2        >1.5cm    113\n",
      "3      negative   2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/66y8yr891nx_wrg5vxt9ppy00000gp/T/ipykernel_14785/1526797899.py:46: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting rows from exams table\n",
      "0        negative\n",
      "1        negative\n",
      "2        negative\n",
      "3        negative\n",
      "4        negative\n",
      "           ...   \n",
      "35718    negative\n",
      "35719        <1cm\n",
      "35720    negative\n",
      "35721    negative\n",
      "35722    negative\n",
      "Name: size_category, Length: 35723, dtype: object\n",
      "  size_category  count\n",
      "0       1.0-1.5    120\n",
      "1          <1cm     61\n",
      "2        >1.5cm    308\n",
      "3      negative  35234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/66y8yr891nx_wrg5vxt9ppy00000gp/T/ipykernel_14785/1526797899.py:46: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "from pandas import ExcelWriter\n",
    "from Bucketsize import nodule_size,connect_to_db,liver_size\n",
    "\n",
    "os.chdir('/Users/kinnaripatel/Desktop/k')\n",
    "path = \"/Users/kinnaripatel/Desktop/k\"\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.json')):     \n",
    "    with open(filename, mode='r') as f:\n",
    "        data = json.load(f)\n",
    "        connection = connect_to_db(data['site_info']['db_name'])\n",
    "        print (data['site_info']['has_facilities'])\n",
    "        cursor = connection.cursor()\n",
    "        if data['site_info']['has_facilities'] == True:\n",
    "            for facility in data['facility_info']:\n",
    "                postgreSQL_select_Query_with_facility = \"\"\"select messages.\"messageId\",\"{}\",\"dateOfBirth\",\"patientVisitFacility\",\"{}\",\"{}\",\"{}\",\"{}\",\"report\",\"has_measure\",\"max_measure\",\"laterality\",\"max_measure_location\",\"max_nodule_shape\",\"max_nodule_calcification\",\"max_nodule_density\",\"max_nodule_margin\",\"max_nodule_lobe\",\"single_multiple_abnormality\" \n",
    "from messages inner join liver as ipn on messages.\"messageId\" = ipn.\"messageId\" \n",
    "where report is not null and \"esIndex\" ilike '{}' and  \"{}\" >=  CURRENT_DATE - INTERVAL '12 months'\"\"\".format(facility['mrn_column_id'],facility['procedure_desc_column_id'],facility['procedure_code_column_id'],facility['exam_date_column_id'],facility['accession_column_id'],facility['facility_id'], facility['exam_date_column_id'])\n",
    "\n",
    "                \n",
    "                cursor.execute(postgreSQL_select_Query_with_facility)\n",
    "                print(\"Selecting rows from exams table\")\n",
    "                exams = cursor.fetchall()\n",
    "                df=pd.DataFrame(list(exams))\n",
    "                file_name = facility['facility_id']+'.xlsx'\n",
    "                df.columns =[\"ID\",\"MRN\",\"DateOfBirth\",\"Facility\",\"Procedure Description\",\"Procedure Code\",\"Exam Date\",\"Accession Number\",\"report\",\"has_measure\",\"max_measure\",\"laterality\",\"max_measure_location\",\"max_nodule_shape\",\"max_nodule_calcification\",\"max_nodule_density\",\"max_nodule_margin\",\"max_nodule_lobe\",\"single_multiple_abnormality\"]\n",
    "                #df.to_csv('sample'+facility['facility_id']+'.csv')\n",
    "                #df['calc']= df['max_measure'].apply[nodule_size]\n",
    "                df['size_category'] = df[\"max_measure\"].apply(liver_size)\n",
    "                print(df['size_category'])\n",
    "                df1=df.groupby('size_category')['size_category'].count().reset_index(name=\"count\")\n",
    "                print(df1)\n",
    "                #df1.to_csv('sample1'+facility['facility_id']+'.csv')\n",
    "                patient_df=df.sort_values('Exam Date').drop_duplicates(subset=['MRN'], keep='last')\n",
    "               # patient_df.to_csv('patientsample'+facility['facility_id']+'.csv')\n",
    "                writer = pd.ExcelWriter(file_name, engine='xlsxwriter')\n",
    "                df.to_excel(writer,sheet_name = 'exams', index=False)\n",
    "                df1.to_excel(writer,sheet_name = 'sizebucket',index=False)\n",
    "                patient_df.to_excel(writer,sheet_name = 'patients', index=False)\n",
    "                writer.save() \n",
    "        else:\n",
    "            postgreSQL_select_Query = \"\"\"select messages.\"messageId\",\"{}\",\"dateOfBirth\",\"patientVisitFacility\",\"{}\",\"{}\",\"{}\",\"{}\",\"report\",\"has_measure\",\"max_measure\",\"laterality\",\"max_measure_location\",\"max_nodule_shape\",\"max_nodule_calcification\",\"max_nodule_density\",\"max_nodule_margin\",\"max_nodule_lobe\",\"single_multiple_abnormality\" \n",
    "from messages inner join liver as ipn on messages.\"messageId\" = ipn.\"messageId\" \n",
    "where report is not null and  \"{}\" >=  '2021-05-01' and \"{}\" < '2021-06-01' \"\"\".format(data['site_info']['mrn_column_id'],data['site_info']['procedure_desc_column_id'],data['site_info']['procedure_code_column_id'],data['site_info']['exam_date_column_id'],data['site_info']['accession_column_id'],data['site_info']['exam_date_column_id'],data['site_info']['exam_date_column_id'])\n",
    "\n",
    "            cursor.execute(postgreSQL_select_Query)\n",
    "            print(\"Selecting rows from exams table\")\n",
    "            exams1 = cursor.fetchall()\n",
    "            df2=pd.DataFrame(list(exams1))\n",
    "            file_name = data['site_info']['site_id']+'.xlsx'\n",
    "            df2.columns =[\"ID\",\"MRN\",\"DateOfBirth\",\"Facility\",\"Procedure Description\",\"Procedure Code\",\"Exam Date\",\"Accession Number\",\"report\",\"has_measure\",\"max_measure\",\"laterality\",\"max_measure_location\",\"max_nodule_shape\",\"max_nodule_calcification\",\"max_nodule_density\",\"max_nodule_margin\",\"max_nodule_lobe\",\"single_multiple_abnormality\"]\n",
    "            #df2.to_csv('sample'+filename+'.csv')\n",
    "            df2['size_category'] = df2[\"max_measure\"].apply(liver_size)\n",
    "            #print(df['size_category'])\n",
    "            df3=df2.groupby('size_category')['size_category'].count().reset_index(name=\"count\")\n",
    "            print(df3)\n",
    "            #df3.to_csv('sample1'+filename+'.csv')\n",
    "            patient_df1=df2.sort_values('Exam Date').drop_duplicates(subset=['MRN'], keep='last')\n",
    "            #patient_df1.to_csv('patientsample'+filename+'.csv')\n",
    "            writer = pd.ExcelWriter(file_name, engine='xlsxwriter')\n",
    "            df2.to_excel(writer,sheet_name = 'exams', index=False)\n",
    "            df3.to_excel(writer,sheet_name = 'sizebucket', index=False)\n",
    "            patient_df1.to_excel(writer,sheet_name = 'patients', index=False)\n",
    "            writer.save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ef560-71c0-4d82-91a4-2410c35b6f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
